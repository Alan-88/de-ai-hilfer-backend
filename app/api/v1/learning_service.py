"""
å­¦ä¹ æ¨¡å—æœåŠ¡å±‚ V2ï¼šåŒ…å«åŸºäºæ¯æ—¥åŠ¨æ€é˜Ÿåˆ—çš„é—´éš”é‡å¤ç®—æ³•
"""

import datetime
import json
import re
import random
from typing import List, Optional, Dict, Any

from sqlalchemy.orm import Session
from sqlalchemy import func

from ai_adapter.llm_router import LLMRouter
from app.core.llm_service import call_llm_service
from app.db import models

# --- ç®—æ³•å¸¸é‡ ---
NEW_WORD_REPETITIONS = 3
REVIEW_WORD_REPETITIONS = 1
FAILED_WORD_REPETITIONS = 2
ACTIVE_POOL_SIZE = 7  # å®šä¹‰"èšç„¦å­¦ä¹ æ± "çš„å¤§å°ï¼Œ7æ˜¯ä¸ªä¸é”™çš„é€‰æ‹©

def _generate_daily_queue(db: Session, limit_new_words: int) -> List[Dict[str, Any]]:
    """
    ã€V4.1 - æœ€ç»ˆç‰ˆã€‘
    - ä½¿ç”¨â€œå­¦ä¹ æ—¥â€ï¼ˆå‡Œæ™¨4ç‚¹ï¼‰ä½œä¸ºæ—¥æœŸåˆ¤æ–­åŸºå‡†ã€‚
    - ä¸¥æ ¼åªä» learning_progress è¡¨ä¸­é€‰å–å•è¯ã€‚
    - æ ¹æ®å•è¯çš„ç†Ÿç»ƒåº¦åŠ¨æ€è®¾ç½®åˆå§‹é‡å¤æ¬¡æ•°ã€‚
    """
    today = (datetime.datetime.now(datetime.timezone.utc) - datetime.timedelta(hours=4)).date()

    review_progress = (
        db.query(models.LearningProgress)
        .filter(func.date(models.LearningProgress.next_review_at) <= today)
        .all()
    )
    
    queue = []
    for progress in review_progress:
        # ã€å…³é”®ä¿®å¤ã€‘æ ¹æ®ç†Ÿç»ƒåº¦åŠ¨æ€è®¾ç½®é‡å¤æ¬¡æ•°
        repetitions = 1 # é»˜è®¤ä¸º1æ¬¡
        if progress.mastery_level <= 1:
            repetitions = 3 # ç”Ÿè¯æˆ–åˆšå­¦çš„è¯ï¼Œé‡å¤3æ¬¡
        elif progress.mastery_level <= 3:
            repetitions = 2 # å­¦ä¹ ä¸­çš„è¯ï¼Œé‡å¤2æ¬¡
        
        queue.append({
            "entry_id": progress.entry_id,
            "repetitions_left": repetitions, 
            "progress": progress
        })
        
    random.shuffle(queue)
    return queue

def get_learning_session_service_v2(
    db: Session,
    daily_session: Dict[str, Any],
    limit_new_words: int = 5
) -> Dict[str, Any]:
    """
    è·å–å­¦ä¹ ä¼šè¯ V3 (æ™ºèƒ½é€‰æ‹©ç‰ˆ):
    - å¼•å…¥"èšç„¦å­¦ä¹ æ± " (Active Pool) æ¦‚å¿µï¼Œå®ç°å±€éƒ¨è½®æ¢ã€‚
    - ç¡®ä¿å•è¯ä¸ä¼šè¿ç»­å‡ºç°ã€‚
    """
    if not daily_session.get("queue"):
        new_queue = _generate_daily_queue(db, limit_new_words)
        daily_session["queue"] = new_queue
        daily_session["initial_count"] = len(new_queue)
        daily_session["last_shown_entry_id"] = None

    active_queue = [word for word in daily_session["queue"] if word["repetitions_left"] > 0]

    if not active_queue:
        # æ¸…ç©ºä¼šè¯ï¼Œä»¥ä¾¿ä¸‹æ¬¡å¯ä»¥é‡æ–°å¼€å§‹
        daily_session["queue"] = []
        daily_session["initial_count"] = 0
        daily_session["last_shown_entry_id"] = None
        return {
            "current_word": None,
            "completed_count": daily_session.get("initial_count", 0),
            "total_count": daily_session.get("initial_count", 0),
            "is_completed": True,
        }

    # --- æ™ºèƒ½é€‰æ‹©ç®—æ³• ---

    # 1. è¿‡æ»¤æ‰ä¸Šä¸€ä¸ªå•è¯ (é¿å…è¿ç»­é‡å¤)
    last_id = daily_session.get("last_shown_entry_id")
    candidate_pool = [word for word in active_queue if word["entry_id"] != last_id]
    
    # å¦‚æœè¿‡æ»¤ååªå‰©ä¸€ä¸ªæˆ–æ²¡æœ‰äº†ï¼Œå°±ä¸è¿‡æ»¤ï¼Œé˜²æ­¢å¡æ­»
    if not candidate_pool:
        candidate_pool = active_queue

    # 2. åˆ›å»º"èšç„¦å­¦ä¹ æ± " (Active Pool)
    # ä¼˜å…ˆé€‰æ‹©é‡å¤æ¬¡æ•°æ›´å¤šçš„å•è¯ï¼Œå®ç°å¯¹éš¾ç‚¹çš„èšç„¦
    candidate_pool.sort(key=lambda x: x["repetitions_left"], reverse=True)
    
    # å–å‰ N ä¸ªæœ€éœ€è¦å­¦ä¹ çš„å•è¯å½¢æˆä¸€ä¸ªå°çš„è½®æ¢æ± 
    focus_pool = candidate_pool[:ACTIVE_POOL_SIZE]

    # 3. ä»èšç„¦æ± ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªå•è¯
    current_word_data = random.choice(focus_pool)
    
    # 4. æ›´æ–°"ä¸Šä¸€ä¸ªå•è¯"çš„è®°å½•
    daily_session["last_shown_entry_id"] = current_word_data["entry_id"]

    # --- åç»­é€»è¾‘ä¸å˜ ---
    entry = db.query(models.KnowledgeEntry).get(current_word_data["entry_id"])

    current_word_for_frontend = {
        "entry_id": entry.id,
        "query_text": entry.query_text,
        "analysis_markdown": entry.analysis_markdown,
        "repetitions_left": current_word_data["repetitions_left"],
        "progress": current_word_data["progress"]
    }

    completed_count = daily_session["initial_count"] - len(set(w["entry_id"] for w in active_queue))

    return {
        "current_word": current_word_for_frontend,
        "completed_count": completed_count,
        "total_count": daily_session["initial_count"],
        "is_completed": False,
    }

def update_learning_progress_service_v2(
    entry_id: int, 
    quality: int, 
    db: Session, 
    daily_session: Dict[str, Any]
):
    """
    æ›´æ–°å­¦ä¹ è¿›åº¦ V2:
    - æ›´æ–°æ¯æ—¥é˜Ÿåˆ—ä¸­çš„é‡å¤æ¬¡æ•°ã€‚
    - å¼‚æ­¥æ›´æ–°æ•°æ®åº“ä¸­çš„ SRS æ•°æ®ã€‚
    """
    # 1. æ›´æ–°å†…å­˜ä¸­çš„æ¯æ—¥é˜Ÿåˆ—
    word_in_queue = next((word for word in daily_session["queue"] if word["entry_id"] == entry_id), None)
    
    if not word_in_queue:
        raise ValueError("å•è¯ä¸åœ¨å½“å‰å­¦ä¹ ä¼šè¯ä¸­")

    if quality < 3:
        # å¦‚æœç­”é”™äº†ï¼Œå¢åŠ é‡å¤æ¬¡æ•°
        word_in_queue["repetitions_left"] += FAILED_WORD_REPETITIONS
    elif quality < 4:
        word_in_queue["repetitions_left"] = max(0, word_in_queue["repetitions_left"] - 1)
    else:
        word_in_queue["repetitions_left"] = max(0, word_in_queue["repetitions_left"] - 2)
        
    # 2. æ›´æ–°æ•°æ®åº“ä¸­çš„æ ¸å¿ƒ SRS æ•°æ®
    progress = (
        db.query(models.LearningProgress)
        .filter(models.LearningProgress.entry_id == entry_id)
        .first()
    )
    
    # å¦‚æœæ˜¯æ–°è¯ï¼Œå…ˆåˆ›å»º LearningProgress è®°å½•
    if not progress:
        progress = models.LearningProgress(entry_id=entry_id)
        db.add(progress)
    
    # æ²¿ç”¨ä¹‹å‰çš„ SM-2 ç®—æ³•æ›´æ–° SRS æ ¸å¿ƒæ•°æ®
    if quality < 3:
        progress.mastery_level = 0
        progress.interval = 0 
        progress.ease_factor = max(1.3, progress.ease_factor - (0.20 if quality < 2 else 0.15))
    else:
        if progress.mastery_level == 0:
            progress.interval = 1
        elif progress.mastery_level == 1:
            progress.interval = 6
        else:
            progress.interval = round(progress.interval * progress.ease_factor)
        
        progress.mastery_level += 1
        progress.ease_factor += (0.1 - (5 - quality) * (0.08 + (5 - quality) * 0.02))
        if progress.ease_factor < 1.3:
            progress.ease_factor = 1.3
            
    today = (datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(hours=4)).date()
    progress.review_count += 1
    progress.last_reviewed_at = today
    progress.next_review_at = progress.last_reviewed_at + datetime.timedelta(days=progress.interval)
    
    db.commit()
    db.refresh(progress)
    
    # æ›´æ–°å†…å­˜é˜Ÿåˆ—ä¸­çš„ progress å¯¹è±¡
    word_in_queue["progress"] = progress

    return progress

# --- ä¿ç•™åŸæœ‰çš„å…¶ä»–æœåŠ¡å‡½æ•° ---

def update_learning_progress_service(progress: models.LearningProgress, quality: int, db: Session):
    """
    åŸºäº SuperMemo-2 (SM-2) ç®€åŒ–ç®—æ³•ï¼Œæ›´æ–°ä¸€ä¸ªå•è¯çš„å­¦ä¹ è¿›åº¦ã€‚
    quality: 0-5 çš„è®°å¿†è´¨é‡è¯„åˆ†ã€‚
    """
    if quality < 3:
        # è®°å¿†å¤±è´¥ï¼Œé‡ç½®å­¦ä¹ å‘¨æœŸ
        progress.mastery_level = 0
        progress.interval = 0  # ç«‹å³éœ€è¦å†æ¬¡å¤ä¹ 
        # å¯¹ ease_factor è¿›è¡Œæƒ©ç½š
        if quality == 2: # çœ‹äº†æç¤ºæ‰è®°èµ·
            progress.ease_factor = max(1.3, progress.ease_factor - 0.15)
        else: # å®Œå…¨å¿˜è®°
            progress.ease_factor = max(1.3, progress.ease_factor - 0.20)
    else:
        # è®°å¿†æˆåŠŸ
        progress.mastery_level += 1
        if progress.mastery_level == 1:
            progress.interval = 1
        elif progress.mastery_level == 2:
            progress.interval = 6
        else:
            progress.interval = round(progress.interval * progress.ease_factor)
        
        # æ ¹æ®è®°å¿†è´¨é‡å¾®è°ƒ ease_factor
        progress.ease_factor += (0.1 - (5 - quality) * (0.08 + (5 - quality) * 0.02))
        if progress.ease_factor < 1.3:
            progress.ease_factor = 1.3
            
    progress.review_count += 1
    progress.last_reviewed_at = datetime.datetime.now(datetime.timezone.utc)
    progress.next_review_at = progress.last_reviewed_at + datetime.timedelta(days=progress.interval)
    
    db.add(progress)
    db.commit()
    return progress


def get_learning_session_service(db: Session, limit_new_words: int = 5) -> dict:
    """
    è·å–å­¦ä¹ ä¼šè¯ï¼šåŒ…æ‹¬éœ€è¦å¤ä¹ çš„å•è¯å’Œæ–°å•è¯
    ä¿®å¤ï¼šåªè¿”å›ç”¨æˆ·æ˜ç¡®æ·»åŠ åˆ°å­¦ä¹ è®¡åˆ’çš„å•è¯
    """
    today = (datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(hours=4)).date()
    
    # è·å–éœ€è¦å¤ä¹ çš„å•è¯ï¼ˆç”¨æˆ·å·²æ·»åŠ åˆ°å­¦ä¹ è®¡åˆ’çš„å•è¯ï¼‰
    review_words = (
        db.query(models.LearningProgress)
        .filter(models.LearningProgress.next_review_at <= today)
        .join(models.KnowledgeEntry)
        .all()
    )
    
    # ä¿®å¤ï¼šä¸å†è‡ªåŠ¨ä»æœªå­¦ä¹ çš„å•è¯ä¸­è·å–æ–°è¯
    # æ–°å•è¯åº”è¯¥åªé€šè¿‡ç”¨æˆ·æ˜ç¡®è°ƒç”¨ /add/{entry_id} æ¥å£æ·»åŠ 
    # è¿™æ ·ç¡®ä¿åªæœ‰ç”¨æˆ·é€‰æ‹©çš„å•è¯æ‰ä¼šè¿›å…¥å­¦ä¹ åˆ—è¡¨
    
    new_words_with_progress = []  # ç©ºåˆ—è¡¨ï¼Œç­‰å¾…ç”¨æˆ·ä¸»åŠ¨æ·»åŠ å•è¯
    
    return {
        "review_words": review_words,
        "new_words": new_words_with_progress
    }


def add_word_to_learning_service(entry_id: int, db: Session) -> models.LearningProgress:
    """
    å°†å•è¯æ·»åŠ åˆ°å­¦ä¹ è®¡åˆ’
    """
    # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨å­¦ä¹ è¿›åº¦
    existing_progress = (
        db.query(models.LearningProgress)
        .filter(models.LearningProgress.entry_id == entry_id)
        .first()
    )
    
    if existing_progress:
        return existing_progress
    
    # åˆ›å»ºæ–°çš„å­¦ä¹ è¿›åº¦è®°å½•
    new_progress = models.LearningProgress(
        entry_id=entry_id,
        next_review_at=datetime.datetime.now(datetime.timezone.utc)  # ç«‹å³å¯å­¦ä¹ 
    )
    
    db.add(new_progress)
    db.commit()
    db.refresh(new_progress)
    
    return new_progress


def get_word_insight_service(entry_id: int, db: Session) -> Optional[str]:
    """
    è·å–å•è¯çš„"æ·±åº¦è§£æ"éƒ¨åˆ†ç”¨äºæç¤º
    """
    entry = db.query(models.KnowledgeEntry).filter(models.KnowledgeEntry.id == entry_id).first()
    if not entry:
        return None
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–"æ·±åº¦è§£æ (Einblicke)"éƒ¨åˆ†
    insight_pattern = r"#### ğŸ§ æ·±åº¦è§£æ \(Einblicke\)(.*?)(?=####|\Z)"
    match = re.search(insight_pattern, entry.analysis_markdown, re.DOTALL | re.IGNORECASE)
    
    if match:
        return match.group(1).strip()
    
    return None


async def generate_dynamic_example_service(entry_id: int, llm_router: LLMRouter, db: Session) -> dict:
    """
    AIåŠ¨æ€ç”Ÿæˆä¾‹å¥
    """
    entry = db.query(models.KnowledgeEntry).filter(models.KnowledgeEntry.id == entry_id).first()
    if not entry:
        raise ValueError("å•è¯ä¸å­˜åœ¨")
    
    prompt = llm_router.config.dynamic_example_sentence_prompt
    response_text = await call_llm_service(llm_router, prompt, entry.query_text)
    
    try:
        result = json.loads(response_text)
        return result
    except json.JSONDecodeError:
        raise ValueError("AIè¿”å›çš„ä¾‹å¥æ ¼å¼é”™è¯¯")


async def generate_synonym_quiz_service(entry_id: int, llm_router: LLMRouter, db: Session) -> dict:
    """
    AIç”ŸæˆåŒä¹‰è¯è¾¨æé€‰æ‹©é¢˜
    """
    entry = db.query(models.KnowledgeEntry).filter(models.KnowledgeEntry.id == entry_id).first()
    if not entry:
        raise ValueError("å•è¯ä¸å­˜åœ¨")
    
    # æå–æ ¸å¿ƒé‡Šä¹‰ç”¨äºå‡ºé¢˜
    core_meaning_pattern = r"\*\s*\*\*[nv\./adj\.]*\*\*\s*\*\*(.*?)\*\*"
    meaning_match = re.search(core_meaning_pattern, entry.analysis_markdown, re.IGNORECASE)
    core_meaning = meaning_match.group(1).strip() if meaning_match else entry.query_text
    
    word_details = f"å•è¯: {entry.query_text}\næ ¸å¿ƒé‡Šä¹‰: {core_meaning}"
    
    prompt = llm_router.config.dynamic_synonym_quiz_prompt.format(word_details=word_details)
    response_text = await call_llm_service(llm_router, prompt)
    
    try:
        result = json.loads(response_text)
        return result
    except json.JSONDecodeError:
        raise ValueError("AIè¿”å›çš„é¢˜ç›®æ ¼å¼é”™è¯¯")
