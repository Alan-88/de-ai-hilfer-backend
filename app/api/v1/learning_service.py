"""
å­¦ä¹ æ¨¡å—æœåŠ¡å±‚ V2ï¼šåŒ…å«åŸºäºæ¯æ—¥åŠ¨æ€é˜Ÿåˆ—çš„é—´éš”é‡å¤ç®—æ³•
"""

import datetime
import json
import re
import random
from typing import List, Optional, Dict, Any

from sqlalchemy.orm import Session
from sqlalchemy import func, cast, Date 

from ai_adapter.llm_router import LLMRouter
from app.core.llm_service import call_llm_service
from app.db import models

# ==============================================================================
# V3 - äºŒå…ƒè®°å¿†æ–¹æ¡ˆé…ç½® (Dual-Memory System Configuration)
# ==============================================================================

# --- å½“æ—¥ä»»åŠ¡ç®¡ç†å™¨é…ç½® ---
GRADUATION_THRESHOLD = 10
QUALITY_SCORE_MAP = {5: 6, 4: 4, 3: 2, 2: -3, 1: -5, 0: -7}
DIFFICULTY_DISCOUNT_MAP = {5: 4, 4: 3, 3: 2}
MAX_DAILY_REPS = 5

# --- é•¿çº¿é‡å¤è°ƒåº¦å™¨é…ç½® ---
SMOOTH_INTERVAL_LADDER = [1, 2, 4, 7, 15]


# ==============================================================================
# V3 - æ–°å¢çš„è¾…åŠ©å‡½æ•° (New Helper Functions for V3)
# ==============================================================================

def calculate_weighted_quality(qualities: List[int]) -> float:
    """
    æ ¹æ®å½“æ—¥æ‰€æœ‰è¯„åˆ†å†å²ï¼Œè®¡ç®—åŠ æƒç»¼åˆåˆ†ï¼Œç”¨äºé•¿çº¿è°ƒåº¦ã€‚
    """
    if not qualities:
        return 0
    if len(qualities) == 1:
        return float(qualities[0])
    
    first_quality = float(qualities[0])
    rest_qualities = [float(q) for q in qualities[1:]]
    
    weighted_score = (first_quality * 0.5) + (sum(rest_qualities) / len(rest_qualities) * 0.5)
    return weighted_score

# ==============================================================================
# æ ¸å¿ƒæœåŠ¡ (Core Service Logic) - å·²æ ¹æ®å®¡æŸ¥æŠ¥å‘Šä¿®å¤
# ==============================================================================

# --- ç®—æ³•å¸¸é‡ (ä¿ç•™) ---
ACTIVE_POOL_SIZE = 7

def get_learning_day() -> datetime.date:
    """
    ã€ä¿®å¤ 4ã€‘ç»Ÿä¸€"å­¦ä¹ æ—¥"çš„è®¡ç®—æ–¹å¼ï¼Œå®šä¹‰ä¸ºæœåŠ¡å™¨æ—¶é—´çš„å‡Œæ™¨4ç‚¹ã€‚
    æ‰€æœ‰ä¸æ—¥æœŸç›¸å…³çš„æ“ä½œéƒ½åº”è°ƒç”¨æ­¤å‡½æ•°ï¼Œç¡®ä¿ä¸€è‡´æ€§ã€‚
    """
    return (datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(hours=4)).date()

def _generate_daily_queue(db: Session, limit_new_words: int) -> List[Dict[str, Any]]:
    """
    ç”Ÿæˆæ¯æ—¥å­¦ä¹ é˜Ÿåˆ— (å·²æ ¹æ®å®¡æŸ¥æŠ¥å‘Šä¿®å¤)
    """
    today = get_learning_day()

    # 1. è·å–åˆ°æœŸå¤ä¹ çš„å•è¯
    review_progress = (
        db.query(models.LearningProgress)
        .filter(cast(models.LearningProgress.next_review_at, Date) <= today)
        .all()
    )

    # 2. è·å–å°šæœªå­¦ä¹ çš„æ–°è¯
    new_word_ids_in_progress = {p.entry_id for p in review_progress}
    num_new_words_needed = limit_new_words
    
    new_entries = []
    if num_new_words_needed > 0:
         new_entries = (
            db.query(models.KnowledgeEntry)  # ã€ä¿®å¤ 1ã€‘æ¨¡å‹åç§°: KnowledgeEntry
            .outerjoin(models.LearningProgress, models.KnowledgeEntry.id == models.LearningProgress.entry_id)
            .filter(models.LearningProgress.entry_id.is_(None)) # ã€ä¿®å¤ 2ã€‘æŸ¥è¯¢è¯­æ³•: .is_(None)
            .limit(num_new_words_needed)
            .all()
        )

    queue = []
    # æ·»åŠ å¤ä¹ å•è¯åˆ°é˜Ÿåˆ—
    for progress in review_progress:
        queue.append({"entry_id": progress.entry_id})

    # æ·»åŠ æ–°å•è¯åˆ°é˜Ÿåˆ—
    for entry in new_entries:
        if entry.id not in new_word_ids_in_progress:
             queue.append({"entry_id": entry.id}) # ã€ä¿®å¤ 1ã€‘å­—æ®µå: entry.id
        
    random.shuffle(queue)
    return queue


def get_learning_session_service_v2(
    db: Session,
    daily_session: Dict[str, Any],
    limit_new_words: int = 5
) -> Dict[str, Any]:
    """
    è·å–å­¦ä¹ ä¼šè¯ (å·²æ ¹æ®å®¡æŸ¥æŠ¥å‘Šä¿®å¤)
    """
    if not daily_session.get("queue"):
        new_queue = _generate_daily_queue(db, limit_new_words)
        daily_session["queue"] = new_queue
        daily_session["word_stats"] = {}
        daily_session["initial_count"] = len(new_queue)
        daily_session["last_shown_entry_id"] = None
    
    active_queue = [
        word_data for word_data in daily_session["queue"]
        if not daily_session.get("word_stats", {}).get(word_data["entry_id"], {}).get("completed_today", False)
    ]

    if not active_queue:
        daily_session.clear() # æ¸…ç©ºä¼šè¯
        return { "current_word": None, "completed_count": daily_session.get("initial_count", 0), "total_count": daily_session.get("initial_count", 0), "is_completed": True }

    last_id = daily_session.get("last_shown_entry_id")
    candidate_pool = [word for word in active_queue if word["entry_id"] != last_id]
    
    if not candidate_pool:
        candidate_pool = active_queue

    focus_pool = candidate_pool[:ACTIVE_POOL_SIZE]
    current_word_data = random.choice(focus_pool)
    daily_session["last_shown_entry_id"] = current_word_data["entry_id"]

    entry = db.query(models.KnowledgeEntry).get(current_word_data["entry_id"]) # ã€ä¿®å¤ 1ã€‘æ¨¡å‹åç§°

    # ã€ä¿®å¤ 5ã€‘å¢åŠ é”™è¯¯å¤„ç†
    if not entry:
        # å¦‚æœæ•°æ®åº“ä¸­æ‰¾ä¸åˆ°è¯¥è¯ï¼Œåˆ™ä»é˜Ÿåˆ—ä¸­ç§»é™¤å¹¶å°è¯•è·å–ä¸‹ä¸€ä¸ª
        daily_session["queue"] = [w for w in daily_session["queue"] if w["entry_id"] != current_word_data["entry_id"]]
        return get_learning_session_service_v2(db, daily_session, limit_new_words)

    # --- ã€æ ¸å¿ƒä¿®å¤ã€‘---
    # é‡æ–°è·å– progress å’Œå½“æ—¥ç»Ÿè®¡æ•°æ®ï¼Œä»¥æ„å»ºå®Œæ•´çš„å‰ç«¯å¯¹è±¡
    progress = db.query(models.LearningProgress).filter_by(entry_id=entry.id).first()
    stats = daily_session.get("word_stats", {}).get(entry.id, {"repetitions": 0})
    
    # ä¼°ç®—ä¸€ä¸ª repetitions_left ç”¨äºæ˜¾ç¤º
    # ä¾‹å¦‚ï¼šå¦‚æœä¸€ä¸ªè¯éœ€è¦10åˆ†æ¯•ä¸šï¼Œå½“å‰2åˆ†ï¼Œå¤§æ¦‚è¿˜éœ€è¦(10-2)/4=2æ¬¡å·¦å³
    estimated_reps_left = max(1, round((GRADUATION_THRESHOLD - stats.get("mastery_score", 0)) / 4))

    current_word_for_frontend = {
        "entry_id": entry.id,
        "query_text": entry.query_text,
        "analysis_markdown": entry.analysis_markdown,
        "repetitions_left": estimated_reps_left, # ä¿®å¤ï¼šæ·»åŠ ä¼°ç®—çš„å‰©ä½™æ¬¡æ•°
        "progress": progress # ä¿®å¤ï¼šæ·»åŠ  progress å¯¹è±¡
    }
    
    completed_count = daily_session["initial_count"] - len(active_queue)

    return {
        "current_word": current_word_for_frontend,
        "completed_count": completed_count,
        "total_count": daily_session["initial_count"],
        "is_completed": False,
    }


# ==============================================================================
# ã€æ ¸å¿ƒä¿®æ”¹ã€‘æ›¿æ¢ update_learning_progress_service_v2
# ==============================================================================

def update_learning_progress_service_v2(
    entry_id: int, 
    quality: int, 
    db: Session, 
    daily_session: Dict[str, Any]
):
    """
    ã€V3 - æœ€ç»ˆç‰ˆã€‘æ›´æ–°å­¦ä¹ è¿›åº¦ï¼Œé‡‡ç”¨äºŒå…ƒè®°å¿†æ–¹æ¡ˆã€‚
    """
    # --- 1. åˆå§‹åŒ– & æ›´æ–°å½“æ—¥ä¼šè¯æ•°æ® ---
    stats = daily_session.setdefault('word_stats', {}).setdefault(entry_id, {
        "qualities": [], "repetitions": 0, "completed_today": False, 
        "mastery_score": 0, "is_difficult": False
    })
    stats['qualities'].append(quality)
    stats['repetitions'] += 1
    
    # --- 2. å½“æ—¥ä»»åŠ¡ç®¡ç†å™¨ï¼šè®¡ç®—â€œå½“æ—¥æŒæ¡ç§¯åˆ†â€ ---
    score_change = 0
    if stats['is_difficult']:
        score_change = DIFFICULTY_DISCOUNT_MAP.get(quality, QUALITY_SCORE_MAP.get(quality, 0))
    else:
        score_change = QUALITY_SCORE_MAP.get(quality, 0)
    stats['mastery_score'] = max(0, stats['mastery_score'] + score_change)

    # --- 3. å½“æ—¥ä»»åŠ¡ç®¡ç†å™¨ï¼šåº”ç”¨â€œåˆè§å®½å®¹â€ & æ›´æ–°å›°éš¾è¯çŠ¶æ€ ---
    if not stats['is_difficult'] and quality < 3:
        fail_count = sum(1 for q in stats['qualities'] if q < 3)
        if fail_count > 1:
            stats['is_difficult'] = True

    # --- 4. å½“æ—¥ä»»åŠ¡ç®¡ç†å™¨ï¼šåˆ¤æ–­å½“æ—¥ä»»åŠ¡æ˜¯å¦å®Œæˆ ---
    task_completed = False
    if stats['mastery_score'] >= GRADUATION_THRESHOLD:
        task_completed = True
    elif stats['repetitions'] >= MAX_DAILY_REPS:
        task_completed = True
    stats['completed_today'] = task_completed

    # --- 5. è·å–æˆ–åˆ›å»ºæ•°æ®åº“å¯¹è±¡ ---
    progress = db.query(models.LearningProgress).filter_by(entry_id=entry_id).first()
    if not progress:
        progress = models.LearningProgress(entry_id=entry_id, ease_factor=2.5)
        db.add(progress)

    today = get_learning_day() # ã€ä¿®å¤ 4ã€‘ç»Ÿä¸€æ—¥æœŸè®¡ç®—

    # --- 6. é•¿çº¿é‡å¤è°ƒåº¦å™¨ï¼šå¦‚æœä»»åŠ¡å®Œæˆï¼Œåˆ™è§„åˆ’æœªæ¥ ---
    if task_completed:
        final_quality = calculate_weighted_quality(stats['qualities'])
        
        is_punished = False
        if stats['repetitions'] >= MAX_DAILY_REPS and stats['mastery_score'] < GRADUATION_THRESHOLD:
            if stats['mastery_score'] < 7:
                 progress.ease_factor = max(1.3, progress.ease_factor - 0.4)
                 progress.mastery_level = 0
            else:
                 progress.ease_factor = max(1.3, progress.ease_factor - 0.2)
            is_punished = True

        if is_punished and progress.mastery_level == 0:
            progress.next_review_at = today + datetime.timedelta(days=1)
        else:
            current_mastery = progress.mastery_level or 0
            if current_mastery < len(SMOOTH_INTERVAL_LADDER):
                progress.interval = SMOOTH_INTERVAL_LADDER[current_mastery]
            else:
                progress.interval = round((progress.interval or 1) * (progress.ease_factor or 2.5))
            
            progress.mastery_level = (progress.mastery_level or 0) + 1
            
            new_ef = (progress.ease_factor or 2.5) + (0.1 - (5 - final_quality) * (0.08 + (5 - final_quality) * 0.02))
            progress.ease_factor = max(1.3, new_ef)
            progress.next_review_at = today + datetime.timedelta(days=progress.interval)
    else:
        progress.next_review_at = today
    
    # --- 7. æ”¶å°¾å·¥ä½œ ---
    progress.last_reviewed_at = today
    if progress.review_count is None:
        progress.review_count = 0
    progress.review_count += 1
    db.commit()
    db.refresh(progress)

    # è¿”å›å½“æ—¥ç»Ÿè®¡æ•°æ®ï¼Œä¸ä½ ç°æœ‰çš„å‰ç«¯æ›´å…¼å®¹
    return {
        "entry_id": progress.entry_id,
        "mastery_level": progress.mastery_level,
        "next_review_at": progress.next_review_at.isoformat(),
        "daily_stats": stats # æŠŠå½“æ—¥çš„è¯¦ç»†æƒ…å†µä¹Ÿè¿”å›
    }

# ==============================================================================
# å…¶ä»–åŸæœ‰å‡½æ•° (ä¿æŒä¸å˜)
# ==============================================================================

def update_learning_progress_service(progress: models.LearningProgress, quality: int, db: Session):
    # ... æ­¤å¤„æ˜¯ä½ æä¾›çš„åŸæœ‰ä»£ç ï¼Œå®Œå…¨æ²¡æœ‰æ”¹åŠ¨ ...
    if quality < 3:
        progress.mastery_level = 0
        progress.interval = 0
        if quality == 2:
            progress.ease_factor = max(1.3, progress.ease_factor - 0.15)
        else:
            progress.ease_factor = max(1.3, progress.ease_factor - 0.20)
    else:
        progress.mastery_level += 1
        if progress.mastery_level == 1:
            progress.interval = 1
        elif progress.mastery_level == 2:
            progress.interval = 6
        else:
            progress.interval = round(progress.interval * progress.ease_factor)
        progress.ease_factor += (0.1 - (5 - quality) * (0.08 + (5 - quality) * 0.02))
        if progress.ease_factor < 1.3:
            progress.ease_factor = 1.3
    progress.review_count += 1
    progress.last_reviewed_at = datetime.datetime.now(datetime.timezone.utc)
    progress.next_review_at = progress.last_reviewed_at + datetime.timedelta(days=progress.interval)
    db.add(progress)
    db.commit()
    return progress

# ... (åé¢æ‰€æœ‰å…¶ä»–å‡½æ•° get_learning_session_service, add_word_to_learning_service ç­‰éƒ½å®Œå…¨ä¿ç•™ï¼Œæ­¤å¤„çœç•¥ä»¥èŠ‚çº¦ç¯‡å¹…) ...
# è¯·å°†ä½ æœ¬åœ°æ–‡ä»¶é‡Œè¯¥å‡½æ•°ä¹‹åçš„æ‰€æœ‰å†…å®¹ï¼Œéƒ½åŸå°ä¸åŠ¨åœ°ä¿ç•™åœ¨ä¸‹é¢ã€‚

def get_learning_session_service(db: Session, limit_new_words: int = 5) -> dict:
    """
    è·å–å­¦ä¹ ä¼šè¯ï¼šåŒ…æ‹¬éœ€è¦å¤ä¹ çš„å•è¯å’Œæ–°å•è¯
    ä¿®å¤ï¼šåªè¿”å›ç”¨æˆ·æ˜ç¡®æ·»åŠ åˆ°å­¦ä¹ è®¡åˆ’çš„å•è¯
    """
    today = (datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(hours=4)).date()
    
    # è·å–éœ€è¦å¤ä¹ çš„å•è¯ï¼ˆç”¨æˆ·å·²æ·»åŠ åˆ°å­¦ä¹ è®¡åˆ’çš„å•è¯ï¼‰
    review_words = (
        db.query(models.LearningProgress)
        .filter(models.LearningProgress.next_review_at <= today)
        .join(models.KnowledgeEntry)
        .all()
    )
    
    # ä¿®å¤ï¼šä¸å†è‡ªåŠ¨ä»æœªå­¦ä¹ çš„å•è¯ä¸­è·å–æ–°è¯
    # æ–°å•è¯åº”è¯¥åªé€šè¿‡ç”¨æˆ·æ˜ç¡®è°ƒç”¨ /add/{entry_id} æ¥å£æ·»åŠ 
    # è¿™æ ·ç¡®ä¿åªæœ‰ç”¨æˆ·é€‰æ‹©çš„å•è¯æ‰ä¼šè¿›å…¥å­¦ä¹ åˆ—è¡¨
    
    new_words_with_progress = []  # ç©ºåˆ—è¡¨ï¼Œç­‰å¾…ç”¨æˆ·ä¸»åŠ¨æ·»åŠ å•è¯
    
    return {
        "review_words": review_words,
        "new_words": new_words_with_progress
    }


def add_word_to_learning_service(entry_id: int, db: Session) -> models.LearningProgress:
    """
    å°†å•è¯æ·»åŠ åˆ°å­¦ä¹ è®¡åˆ’
    """
    # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨å­¦ä¹ è¿›åº¦
    existing_progress = (
        db.query(models.LearningProgress)
        .filter(models.LearningProgress.entry_id == entry_id)
        .first()
    )
    
    if existing_progress:
        return existing_progress
    
    # åˆ›å»ºæ–°çš„å­¦ä¹ è¿›åº¦è®°å½•
    new_progress = models.LearningProgress(
        entry_id=entry_id,
        next_review_at=datetime.datetime.now(datetime.timezone.utc)  # ç«‹å³å¯å­¦ä¹ 
    )
    
    db.add(new_progress)
    db.commit()
    db.refresh(new_progress)
    
    return new_progress


def get_word_insight_service(entry_id: int, db: Session) -> Optional[str]:
    """
    è·å–å•è¯çš„"æ·±åº¦è§£æ"éƒ¨åˆ†ç”¨äºæç¤º
    """
    entry = db.query(models.KnowledgeEntry).filter(models.KnowledgeEntry.id == entry_id).first()
    if not entry:
        return None
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–"æ·±åº¦è§£æ (Einblicke)"éƒ¨åˆ†
    insight_pattern = r"#### ğŸ§ æ·±åº¦è§£æ \(Einblicke\)(.*?)(?=####|\Z)"
    match = re.search(insight_pattern, entry.analysis_markdown, re.DOTALL | re.IGNORECASE)
    
    if match:
        return match.group(1).strip()
    
    return None


async def generate_dynamic_example_service(entry_id: int, llm_router: LLMRouter, db: Session) -> dict:
    """
    AIåŠ¨æ€ç”Ÿæˆä¾‹å¥
    """
    entry = db.query(models.KnowledgeEntry).filter(models.KnowledgeEntry.id == entry_id).first()
    if not entry:
        raise ValueError("å•è¯ä¸å­˜åœ¨")
    
    prompt = llm_router.config.dynamic_example_sentence_prompt
    response_text = await call_llm_service(llm_router, prompt, entry.query_text)
    
    try:
        result = json.loads(response_text)
        return result
    except json.JSONDecodeError:
        raise ValueError("AIè¿”å›çš„ä¾‹å¥æ ¼å¼é”™è¯¯")


async def generate_synonym_quiz_service(entry_id: int, llm_router: LLMRouter, db: Session) -> dict:
    """
    AIç”ŸæˆåŒä¹‰è¯è¾¨æé€‰æ‹©é¢˜
    """
    entry = db.query(models.KnowledgeEntry).filter(models.KnowledgeEntry.id == entry_id).first()
    if not entry:
        raise ValueError("å•è¯ä¸å­˜åœ¨")
    
    # æå–æ ¸å¿ƒé‡Šä¹‰ç”¨äºå‡ºé¢˜
    core_meaning_pattern = r"\*\s*\*\*[nv\./adj\.]*\*\*\s*\*\*(.*?)\*\*"
    meaning_match = re.search(core_meaning_pattern, entry.analysis_markdown, re.IGNORECASE)
    core_meaning = meaning_match.group(1).strip() if meaning_match else entry.query_text
    
    word_details = f"å•è¯: {entry.query_text}\næ ¸å¿ƒé‡Šä¹‰: {core_meaning}"
    
    prompt = llm_router.config.dynamic_synonym_quiz_prompt.format(word_details=word_details)
    response_text = await call_llm_service(llm_router, prompt)
    
    try:
        result = json.loads(response_text)
        return result
    except json.JSONDecodeError:
        raise ValueError("AIè¿”å›çš„é¢˜ç›®æ ¼å¼é”™è¯¯")
