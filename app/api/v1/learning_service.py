"""
å­¦ä¹ æ¨¡å—æœåŠ¡å±‚ï¼šåŒ…å«é—´éš”é‡å¤ç®—æ³•å’Œå­¦ä¹ ç›¸å…³ä¸šåŠ¡é€»è¾‘
"""

import datetime
import json
import re
from typing import List, Optional

from sqlalchemy.orm import Session

from ai_adapter.llm_router import LLMRouter
from app.core.llm_service import call_llm_service
from app.db import models


def update_learning_progress_service(progress: models.LearningProgress, quality: int, db: Session):
    """
    åŸºäº SuperMemo-2 (SM-2) ç®€åŒ–ç®—æ³•ï¼Œæ›´æ–°ä¸€ä¸ªå•è¯çš„å­¦ä¹ è¿›åº¦ã€‚
    quality: 0-5 çš„è®°å¿†è´¨é‡è¯„åˆ†ã€‚
    """
    if quality < 3:
        # è®°å¿†å¤±è´¥ï¼Œé‡ç½®å­¦ä¹ å‘¨æœŸ
        progress.mastery_level = 0
        progress.interval = 1
        # å¯¹ ease_factor è¿›è¡Œæƒ©ç½š
        if quality == 2: # çœ‹äº†æç¤ºæ‰è®°èµ·
            progress.ease_factor = max(1.3, progress.ease_factor - 0.15)
        else: # å®Œå…¨å¿˜è®°
            progress.ease_factor = max(1.3, progress.ease_factor - 0.20)
    else:
        # è®°å¿†æˆåŠŸ
        progress.mastery_level += 1
        if progress.mastery_level == 1:
            progress.interval = 1
        elif progress.mastery_level == 2:
            progress.interval = 6
        else:
            progress.interval = round(progress.interval * progress.ease_factor)
        
        # æ ¹æ®è®°å¿†è´¨é‡å¾®è°ƒ ease_factor
        progress.ease_factor += (0.1 - (5 - quality) * (0.08 + (5 - quality) * 0.02))
        if progress.ease_factor < 1.3:
            progress.ease_factor = 1.3
            
    progress.review_count += 1
    progress.last_reviewed_at = datetime.datetime.utcnow()
    progress.next_review_at = progress.last_reviewed_at + datetime.timedelta(days=progress.interval)
    
    db.add(progress)
    db.commit()
    return progress


def get_learning_session_service(db: Session, limit_new_words: int = 5) -> dict:
    """
    è·å–å­¦ä¹ ä¼šè¯ï¼šåŒ…æ‹¬éœ€è¦å¤ä¹ çš„å•è¯å’Œæ–°å•è¯
    """
    today = datetime.datetime.utcnow()
    
    # è·å–éœ€è¦å¤ä¹ çš„å•è¯
    review_words = (
        db.query(models.LearningProgress)
        .filter(models.LearningProgress.next_review_at <= today)
        .join(models.KnowledgeEntry)
        .all()
    )
    
    # è·å–æ–°å•è¯ï¼ˆè¿˜æ²¡æœ‰å­¦ä¹ è¿›åº¦çš„å•è¯ï¼‰
    # ä¿®å¤ï¼šè·å–æ‰€æœ‰å·²æœ‰å­¦ä¹ è¿›åº¦çš„å•è¯IDï¼Œè€Œä¸æ˜¯ä»…ä»…å¤ä¹ å•è¯
    all_learned_progress = db.query(models.LearningProgress.entry_id).all()
    all_learned_entry_ids = {progress.entry_id for progress in all_learned_progress}
    
    new_words = (
        db.query(models.KnowledgeEntry)
        .filter(models.KnowledgeEntry.id.notin_(all_learned_entry_ids))
        .filter(models.KnowledgeEntry.entry_type == 'WORD')
        .limit(limit_new_words)
        .all()
    )
    
    # ä¸ºæ–°å•è¯åˆ›å»ºå­¦ä¹ è¿›åº¦è®°å½•ï¼Œç¡®ä¿å‰ç«¯å¯ä»¥æ­£å¸¸æäº¤å¤ä¹ ç»“æœ
    new_words_with_progress = []
    for word in new_words:
        # åˆ›å»ºå­¦ä¹ è¿›åº¦è®°å½•
        new_progress = models.LearningProgress(
            entry_id=word.id,
            next_review_at=datetime.datetime.utcnow()  # ç«‹å³å¯å­¦ä¹ 
        )
        db.add(new_progress)
        db.commit()
        db.refresh(new_progress)
        
        # å°†æ–°å•è¯åŒ…è£…æˆä¸å¤ä¹ å•è¯ç›¸åŒçš„æ•°æ®ç»“æ„
        new_words_with_progress.append(new_progress)
    
    return {
        "review_words": review_words,
        "new_words": new_words_with_progress  # è¿”å›å¸¦æœ‰å­¦ä¹ è¿›åº¦è®°å½•çš„æ–°å•è¯
    }


def add_word_to_learning_service(entry_id: int, db: Session) -> models.LearningProgress:
    """
    å°†å•è¯æ·»åŠ åˆ°å­¦ä¹ è®¡åˆ’
    """
    # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨å­¦ä¹ è¿›åº¦
    existing_progress = (
        db.query(models.LearningProgress)
        .filter(models.LearningProgress.entry_id == entry_id)
        .first()
    )
    
    if existing_progress:
        return existing_progress
    
    # åˆ›å»ºæ–°çš„å­¦ä¹ è¿›åº¦è®°å½•
    new_progress = models.LearningProgress(
        entry_id=entry_id,
        next_review_at=datetime.datetime.utcnow()  # ç«‹å³å¯å­¦ä¹ 
    )
    
    db.add(new_progress)
    db.commit()
    db.refresh(new_progress)
    
    return new_progress


def get_word_insight_service(entry_id: int, db: Session) -> Optional[str]:
    """
    è·å–å•è¯çš„"æ·±åº¦è§£æ"éƒ¨åˆ†ç”¨äºæç¤º
    """
    entry = db.query(models.KnowledgeEntry).filter(models.KnowledgeEntry.id == entry_id).first()
    if not entry:
        return None
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–"æ·±åº¦è§£æ (Einblicke)"éƒ¨åˆ†
    insight_pattern = r"#### ğŸ§ æ·±åº¦è§£æ \(Einblicke\)(.*?)(?=####|\Z)"
    match = re.search(insight_pattern, entry.analysis_markdown, re.DOTALL | re.IGNORECASE)
    
    if match:
        return match.group(1).strip()
    
    return None


async def generate_dynamic_example_service(entry_id: int, llm_router: LLMRouter, db: Session) -> dict:
    """
    AIåŠ¨æ€ç”Ÿæˆä¾‹å¥
    """
    entry = db.query(models.KnowledgeEntry).filter(models.KnowledgeEntry.id == entry_id).first()
    if not entry:
        raise ValueError("å•è¯ä¸å­˜åœ¨")
    
    prompt = llm_router.config.dynamic_example_sentence_prompt
    response_text = await call_llm_service(llm_router, prompt, entry.query_text)
    
    try:
        result = json.loads(response_text)
        return result
    except json.JSONDecodeError:
        raise ValueError("AIè¿”å›çš„ä¾‹å¥æ ¼å¼é”™è¯¯")


async def generate_synonym_quiz_service(entry_id: int, llm_router: LLMRouter, db: Session) -> dict:
    """
    AIç”ŸæˆåŒä¹‰è¯è¾¨æé€‰æ‹©é¢˜
    """
    entry = db.query(models.KnowledgeEntry).filter(models.KnowledgeEntry.id == entry_id).first()
    if not entry:
        raise ValueError("å•è¯ä¸å­˜åœ¨")
    
    # æå–æ ¸å¿ƒé‡Šä¹‰ç”¨äºå‡ºé¢˜
    core_meaning_pattern = r"\*\s*\*\*[nv\./adj\.]*\*\*\s*\*\*(.*?)\*\*"
    meaning_match = re.search(core_meaning_pattern, entry.analysis_markdown, re.IGNORECASE)
    core_meaning = meaning_match.group(1).strip() if meaning_match else entry.query_text
    
    word_details = f"å•è¯: {entry.query_text}\næ ¸å¿ƒé‡Šä¹‰: {core_meaning}"
    
    prompt = llm_router.config.dynamic_synonym_quiz_prompt.format(word_details=word_details)
    response_text = await call_llm_service(llm_router, prompt)
    
    try:
        result = json.loads(response_text)
        return result
    except json.JSONDecodeError:
        raise ValueError("AIè¿”å›çš„é¢˜ç›®æ ¼å¼é”™è¯¯")
